Step 1: Creating an EKS role
Our first step is to set up a new IAM role with EKS permissions.

Open the IAM console, select Roles on the left and then click the Create Role button at the top of the page.

Enter a name for the role (e.g. eksrole) and hit the Create role button at the bottom of the page to create the IAM role.

Step 2: Creating a VPC for EKS
Next, we’re going to create a separate VPC—a Virtual Private Cloud that protects communication between worker nodes and the AWS Kubernetes API server— for our EKS cluster. To do this, we’re going to use a CloudFormation template that contains all the necessary EKS-specific ingredients for setting up the VPC.

Open up CloudFormation, and click the Create new stack button.

On the Select template page, enter the URL of the CloudFormation YAML in the relevant section:

https://amazon-eks.s3-us-west-2.amazonaws.com/cloudformation/2019-01-
09/amazon-eks-vpc-sample.yaml

Give the VPC a name, leave the default network configurations as-is, and click Next.

On the Options page, you can leave the default options untouched and then click Next.

Step 3: Creating the EKS cluster
As mentioned above, we will use the AWS CLI to create the Kubernetes cluster. To do this, use the following command:

aws eks --region us-east-1 create-cluster --name demo --role-arn
arn:aws:iam::011173820421:role/eksServiceRole --resources-vpc-config 
subnetIds=subnet-06d3631efa685f604,subnet-0f435cf42a1869282,
subnet-03c954ee389d8f0fd,securityGroupIds=sg-0f45598b6f9aa110a

It takes about 5 minutes before your cluster is created. You can ping the status of the command using this CLI command:

aws eks --region us-east-1 describe-cluster --name demo --query 
cluster.status
Copy
The output displayed will be:

"CREATING"

Once the status changes to “ACTIVE”, we can proceed with updating our kubeconfig file with the information on the new cluster so kubectl can communicate with it.

To do this, we will use the AWS CLI update-kubeconfig command (be sure to replace the region and cluster name to fit your configurations):

aws eks --region us-east-1 update-kubeconfig --name demo
Copy
You should see the following output:

Added new context arn:aws:eks:us-east-1:011173820421:cluster/demo to 
/Users/rohit/.kube/config
Copy
We can now test our configurations using the kubectl get svc command:

kubectl get svc

Step 4: Launching Kubernetes worker nodes
Now that we’ve set up our cluster and VPC networking, we can now launch Kubernetes worker nodes. To do this, we will again use a CloudFormation template.

Open CloudFormation, click Create Stack, and this time use the following template URL:

https://amazon-eks.s3-us-west-2.amazonaws.com/cloudformation/2019-01-
09/amazon-eks-nodegroup.yaml

Clicking Next, name your stack, and in the EKS Cluster section enter the following details:

ClusterName – the name of your Kubernetes cluster (e.g. demo)
ClusterControlPlaneSecurityGroup – the same security group you used for creating the cluster in previous step.
NodeGroupName – a name for your node group.
NodeAutoScalingGroupMinSize – leave as-is. The minimum number of nodes that your worker node Auto Scaling group can scale to.
NodeAutoScalingGroupDesiredCapacity – leave as-is. The desired number of nodes to scale to when your stack is created.
NodeAutoScalingGroupMaxSize – leave as-is. The maximum number of nodes that your worker node Auto Scaling group can scale out to.
NodeInstanceType – leave as-is. The instance type used for the worker nodes.
NodeImageId – the Amazon EKS worker node AMI ID for the region you’re using. For us-east-1, for example: ami-0c5b63ec54dd3fc38
KeyName – the name of an Amazon EC2 SSH key pair for connecting with the worker nodes once they launch.
BootstrapArguments – leave empty. This field can be used to pass optional arguments to the worker nodes bootstrap script.
VpcId – enter the ID of the VPC you created in Step 2 above.
Subnets – select the three subnets you created in Step 2 above.

Proceed to the Review page, select the check-box at the bottom of the page acknowledging that the stack might create IAM resources, and click Create.

CloudFormation creates the worker nodes with the VPC settings we entered — three new EC2 instances are created using the

As before, once the stack is created, open Outputs tab:

To do this, first download the AWS authenticator configuration map:

curl -O 
https://amazon-eks.s3-us-west-2.amazonaws.com/cloudformation/2019-01-09
/aws-auth-cm.yaml
Copy
Open the file and replace the rolearn with the ARN of the NodeInstanceRole created above:

apiVersion: v1
kind: ConfigMap
metadata:
  name: aws-auth
  namespace: kube-system
data:
  mapRoles: |
    - rolearn: <ARN of instance role>
      username: system:node:{{EC2PrivateDNSName}}
      groups:
        - system:bootstrappers
        - system:nodes
Copy
Save the file and apply the configuration:

kubectl apply -f aws-auth-cm.yaml
Copy
You should see the following output:

configmap/aws-auth created
Copy
Use kubectl to check on the status of your worker nodes:

kubectl get nodes --watch

Step 5: Making the website on kubernetes cluster

Create a Kubernetes namespace for the sample app.

->kubectl create namespace <my-namespace>

Deploy the application.

->kubectl apply -f <sample-service.yaml>

View all resources that exist in the my-namespace namespace.

->kubectl get all -n my-namespace

Output

NAME                                 READY   STATUS    RESTARTS   AGE
pod/my-deployment-776d8f8fd8-78w66   1/1     Running   0          27m
pod/my-deployment-776d8f8fd8-dkjfr   1/1     Running   0          27m
pod/my-deployment-776d8f8fd8-wmqj6   1/1     Running   0          27m

NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
service/my-service   ClusterIP   10.100.190.12   <none>        80/TCP    32m

NAME                            READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/my-deployment   3/3     3            3           27m

NAME                                       DESIRED   CURRENT   READY   AGE
replicaset.apps/my-deployment-776d8f8fd8   3         3         3       27m

View the details of the deployed service.

->kubectl -n <my-namespace> describe service <my-service>
